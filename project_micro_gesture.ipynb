{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'training'  # Folder with class subdirectories\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 32\n",
    "EPOCHS = 10\n",
    "IMAGE_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PATIENCE = 3 \n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet means\n",
    "                         [0.229, 0.224, 0.225])   # ImageNet stds\n",
    "])\n",
    "\n",
    "\n",
    "class GestureDataset(datasets.ImageFolder):\n",
    "    def __getitem__(self, index):\n",
    "        path, label = self.samples[index]\n",
    "        video_id = os.path.basename(path).split('.')[0]  # e.g., 4215\n",
    "        image = self.loader(path)\n",
    "        image = self.transform(image)\n",
    "        return image, label, video_id\n",
    "\n",
    "\n",
    "full_dataset = GestureDataset(DATA_DIR, transform=transform)\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.6159, Train Accuracy: 0.4970\n",
      "Validation Accuracy: 0.5756, Validation Loss: 1.3342\n",
      "Epoch 2/10, Loss: 1.1916, Train Accuracy: 0.6143\n",
      "Validation Accuracy: 0.6188, Validation Loss: 1.1499\n",
      "Epoch 3/10, Loss: 0.9810, Train Accuracy: 0.6707\n",
      "Validation Accuracy: 0.6607, Validation Loss: 1.0399\n",
      "Epoch 4/10, Loss: 0.8211, Train Accuracy: 0.7197\n",
      "Validation Accuracy: 0.6876, Validation Loss: 0.9699\n",
      "Epoch 5/10, Loss: 0.6909, Train Accuracy: 0.7595\n",
      "Validation Accuracy: 0.6916, Validation Loss: 0.9176\n",
      "Epoch 6/10, Loss: 0.5886, Train Accuracy: 0.7882\n",
      "Validation Accuracy: 0.7001, Validation Loss: 0.9569\n",
      "Epoch 7/10, Loss: 0.5094, Train Accuracy: 0.8148\n",
      "Validation Accuracy: 0.7152, Validation Loss: 0.9052\n",
      "Epoch 8/10, Loss: 0.4410, Train Accuracy: 0.8366\n",
      "Validation Accuracy: 0.7077, Validation Loss: 0.9326\n",
      "Epoch 9/10, Loss: 0.3874, Train Accuracy: 0.8524\n",
      "Validation Accuracy: 0.7259, Validation Loss: 0.9203\n",
      "Epoch 10/10, Loss: 0.3466, Train Accuracy: 0.8699\n",
      "Validation Accuracy: 0.7246, Validation Loss: 0.9597\n"
     ]
    }
   ],
   "source": [
    "class EnhancedResNet(nn.Module):\n",
    "    def __init__(self, num_classes=32):\n",
    "        super(EnhancedResNet, self).__init__()\n",
    "        \n",
    "        # Load pre-trained ResNet50\n",
    "        self.resnet = models.resnet50( weights=models.ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Remove the original fully connected layer\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        # Additional CNN layers\n",
    "        self.extra_conv = nn.Sequential(\n",
    "            nn.Conv2d(2048, 1024, kernel_size=3, padding=1),  # Additional conv layer\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Global average pooling\n",
    "        )\n",
    "        \n",
    "        # Final classifier\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # ResNet feature extraction\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "        \n",
    "        x = self.resnet.layer1(x)\n",
    "        x = self.resnet.layer2(x)\n",
    "        x = self.resnet.layer3(x)\n",
    "        x = self.resnet.layer4(x)  # Output shape: [batch, 2048, 7, 7]\n",
    "        \n",
    "        # Additional CNN processing\n",
    "        x = self.extra_conv(x)  # Output shape: [batch, 1024, 1, 1]\n",
    "        \n",
    "        # Flatten and classify\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = EnhancedResNet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    global best_val_loss, patience_counter\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for images, labels, _ in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "\n",
    "        train_accuracy = correct_train / total_train\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "        # Validate after each epoch\n",
    "        val_loss = validate_model()\n",
    "\n",
    "        # Check for early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "\n",
    "def validate_model():\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 Accuracy: 85.71%\n",
      "Top-5 Accuracy: 99.52%\n"
     ]
    }
   ],
   "source": [
    "model = EnhancedResNet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "# Load the saved state_dict\n",
    "model.load_state_dict(torch.load(r'ours_state_dict.pt'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "def topk_accuracy(output, target, k=5):\n",
    "    with torch.no_grad():\n",
    "        # Get the top k predictions\n",
    "        _, pred = output.topk(k, 1, True, True)\n",
    "        \n",
    "        # Check if the target label is in the top k predictions\n",
    "        correct = pred.eq(target.view(-1, 1).expand_as(pred))\n",
    "        \n",
    "        # Calculate the average accuracy\n",
    "        topk_acc = correct.float().sum(1).mean().item()\n",
    "        return topk_acc\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "top1_correct = 0\n",
    "top5_correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, _ in val_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate top-1 accuracy\n",
    "        top1_correct += topk_accuracy(outputs, labels, k=1) * images.size(0)\n",
    "        \n",
    "        # Calculate top-5 accuracy\n",
    "        top5_correct += topk_accuracy(outputs, labels, k=5) * images.size(0)\n",
    "        \n",
    "        total += images.size(0)\n",
    "\n",
    "top1_acc = top1_correct / total\n",
    "top5_acc = top5_correct / total\n",
    "\n",
    "print(f\"Top-1 Accuracy: {top1_acc * 100:.2f}%\")\n",
    "print(f\"Top-5 Accuracy: {top5_acc * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
